운영체제 강의 정리(KOCW 반효경 교수님 강의)

* 인터럽트
일반적으로는 하드웨어 인터럽트를 말한다. 이것은 IO 작업 같은 것을 운영체제가 직접
제어권을 가지고 'CPU를 사용하는 것'이다.
반면 소프트웨어 인터럽트는 소프트웨어에서 운영체제에 CPU 사용을 허가받는 것이다.
시스템콜을 이용하여 운영체제에 요청을 보내면 자원을 받을 수 있다.
CPU에는 mode bit이라는 0과 1로 이루어진 상태 변수가 있는데 이것이 1이냐 0이냐에 따라서
OS에서의 직접 접근, 사용자 프로그램에서의 접근 모드를 바꾼다. 

* 입출력 방식
동기식 입출력: io가 끝나야 제어가 사용자 프로그램으로 넘어감
비동기식 입출력: io가 끝나지 않아도 제어가 사용자에게 넘어감

* DMA(Direct Memory Access)
빠른 입출력 장치를 메모리에 가까운 속도로 처리하기 위해 사용.
CPU 중재 없이 device controller가 device의 buffer storage 내용을 메모리에
block 단위로 직접 전송.

* 프로그램은 어떻게 동작하는가
프로그램들은 각자 virtual memory를 할당받는다.
그리고 필요한 것만 메모리에 올리게 된다.
필요 없는 것은 디스크의 swap area에 놓이게 된다.

메모리에는 사용자 프로그램이 올라가기 이전에 운영체제 커널이 항상 상주한다.
이 커널이 시스템콜, 인터럽트 처리, 자원관리 등을 다 실행하는 것이다.
그리고 내부에 운영체제용 자료구조들도 정의되어 있다.
그리고 PCB도 이 안에 들어있다.

어떤 프로그램이 시스템콜을 사용할 때 CPU는 user mode와 kernel mode를 왔다갔다한다.
프로그램이 종료될 때까지 이 과정을 반복한다.

* 프로세스와 스레드
문맥 교환은 CPU에서 사용하고 있는 프로세스의 상태를 커널이 기록하는 것이다.

시스템 콜이나 인터럽트 발생시 반드시 context switcing이 일어나는 것은 아니다.
사용자프로세스->운영체제->사용자프로세스 이 과정은 문맥 교환 상황이 아니다.
사용자프로세스a->운영체제->사용자프로세스b 이 과정은 문맥 교환이 일어나는 상황이다.

스레드는 프로세스의 주소공간의 Stack 안에 각자의 Stack 공간을 배정받는다.
PCB 내에서도 CPU 수행과 관련된 정보(register, program counter)를 통해서
관리된다.

스레드 사용의 이유: 반응성, 자원공유로 인한 공간 절약, 경제적(컨텍스트 스위치),
cpu가 여러개일 경우에는 다른 cpu에서 병렬적으로 일을 할 수도 있다.

프로세스 간에는 직접 메시지를 전달하는 것은 불가능하다.
대신 커널을 통해서 보내는 것이 가능하다. 또한 공유 공간을 지정하는 것도 가능은 하다. 

* Process Synchronization
Race condition과 관련된 개념이다.
여기에선 커널의 코드가 공유되기 때문에 그 코드 상에서 문제가 생길 수 있는 것을
방지하는 것과 관련된 것이 나온다.

* 메모리 관리
논리적인 주소는 즉 가상 주소라고 말할 수 있다.
각 프로세스마다 0번지부터 시작하는 메모리가 있다.

* 주소 바인딩
이 가상 주소가 실제 메모리의 주소에 바인딩 되는 방식은 여러가지 방식이 있다.
Compile time, Load time, Execution(runtime) time binding의 세 가지이다.
-compile: 컴파일 시점에 물리적 메모리로 바로 올림. 비효율적이다. 안 쓴다.
프로그램이 하나면 상관 없어서 쓰기도 한다.
-load: 시작해서 메모리에 올라갈 때 바인딩된다.
-runtime: 시작 이후 해당 기능을 써야할 때 바인딩된다. 대부분 이걸 쓴다.
주소변환용 하드웨어의 지원이 필요하다. Memory-Management Unit이 그것인데, 
MMU는 레지스터를 이용해서 주소변환 작업을 실행한다.

* Dynamic Loading
프로세스 전체를 메모리에 미리 다 올리지 않고 해당 루틴이 불릴 때 메모리에 올리는 것.
자주 사용되는 코드를 올려놓기. 프로그램 자체에서 구현 가능

* Swapping
프로세스를 일시적으로 메모리에서 디스크로 쫒아내는 것을 말하는데,
이게 중기 스케쥴러가 하는 일이다.
우선순위가 낮은 프로그램들을 디스크로 내려놓는다.
런타임 바인딩이어야 효율이 좋다. 주소를 왔다갔다할 때 아무데나 놓을 수 있기 때문.

* 물리 메모리 관리
사용자 프로세스를 할당하는 방법은 두 가지이다.
연속적인 방법(파티션 배분): 고정/가변 분할 방식. 기존 나뉘어있는 분할 공간으로 배치된다.
비연속적인 방법(페이징, 세그먼테이션): 현대의 시스템, 하나의 프로세스가 메모리의 여러 영역에
분산되어서 올라간다.

* 페이징
- virtual memory를 동일한 사이즈의 page 단위로 나눔
- 일부는 메모리에, 일부는 디스크에 저장한다.
물리메모리를 동일한 프레임으로, 논리 메모리를 동일한 페이지(=프레임)로 나눈다.
전체 메모리가 페이지의 배수가 안될 수도 있다. 이럴 때는, 내부 조각이 생길 수 있다.
물리 메모리에 올릴 때는 다이나믹하게 비연속적으로 배치된다.
- 어떤 물리 메모리에 올라가있는지는 페이지 테이블에 저장되어 있다.
페이지 테이블 자체는 메모리에 올라가 있다. 그래서 결국 메모리를 두 번 접근하게 된다.
그런데 이것 자체가 비용이 큰 작업이기 때문에 보조 하드웨어가 있다.
TLB(translation look-side buffer)라는 것인데 CPU와 메모리 사이에 놓을 수 있다.
TLB는 페이징을 위한 캐시라고 보면 된다.
- 또한 컴퓨터들의 메모리가 엄청 큰 관계로 최근의 페이징 테이블은 두 단계로 나뉘어 구성된다.
페이징 테이블의 페이징 테이블! 이렇게 하면 자주 사용하는 것들로만 효율적으로 구성 가능하다.
- Multilevel Paging: 두 단계가 끝이 아니다. 더욱 많은 단계로 사용할 수 있다.
이렇게 하면 테이블을 위한 공간을 줄일 수 있지만, 메모리를 여러 번 거치게 된다.
하지만 TLB가 있어서 그렇게 속도가 많이 느려지지는 않는다.

* 세그먼테이션
페이징처럼 세그먼트 테이블이 있다. 세그먼트는 길이가 다 다르기 때문에 테이블에 기록된다. 
세그먼테이션은 페이징하고 다른 점이, 길이에 관련된 부분이 많다.
세그먼테이션은 길이가 다르기 때문에 오프셋이 어딘지를 기록해 놓는 것이 중요하다.
크기가 불균형하다는 점은 결국 fragment를 많이 발생시킨다.
의미 단위로 데이터를 나눈다는 점에서는 권한(보안)이나 공유 측면에 있어서 페이징보다 효과적이다.
특정 세그먼트에 특정 권한을 주고 싶다면 줄 수 있지만, 페이징은 불가능하다.
또한 특정 세그먼트를 공유하는 것도 가능하다. 

* 페이징 & 세그먼테이션 혼합
크기단위인 페이징, 의미단위인 세그먼트. 그 둘을 합친 세그먼트를 페이지로 구성하는 기법이다.
먼저 세그먼트에 대하여 주소 변환을 하게 되고,
그 세그먼트들을 가지고 세그먼트 당 페이징을 하는 방법이다.
세그먼테이션만 쓰는 시스템은 없다. 같이 쓰는 것이 좋다.

* Demand Paging(요구 페이징)
페이징을 실제로 이 기법을 이용해서 쓴다.
실제로 필요할 때 page를 메모리에 올리는 것을 말한다.
i/o의 양이 감소하고, 메모리 사용량도 감소, 응답 시간도 빠르다.
페이지 테이블의 valid-invalid bit 공간에 invalid인 것들은 디스크에 존재하게 된다.

* 페이지 폴트
요청한 페이지가 메모리에 올라가 있지 않을 경우 Page Fault가 일어난다.
이렇게 되면 MMU가 trap을 발생시키고, 이제 운영체제에게 역할이 돌아간다.
커널에서는 page fault handler가 시작된다.
여기에서 필요한 데이터를 메모리로 올려놓는 역할을 하게 된다. 

page-falut rate 확률은 대부분은 잘 나지 않는다.
한 번 났을 때의 시간은 조금 길다.

OS에서는 빈 페이지가 없을 경우에 어떤 frame을 빼앗아올지 결정해야 하고, 어떤 것을
뺏을지에 대한 알고리즘이 따로 있다. 이걸 replacement algorithm이라고 부른다.
replacement algorithm은 page-fault rate를 낮추는 것이 목표이다.
이 알고리즘으로 fifo, LRU(가장 많이 사용), LFU(least frequently used)가 있다.

* 페이징 자체적으로는 어떤 것을 쫓아낼지 다른 알고리즘을 사용해야 한다.
페이징 폴트 상황이 아니더라도 메모리 교체를 할 수 있어야 한다.
Clock Algorithm이 대표적이다.
LRU의 근사 알고리즘이라고 볼 수 있다. NRU(not recently used)라고도 불린다.
페이지 테이블에서 reference bit이라는 것을 관리하면서 어떤 것을 대체할지 결정한다.
시계모양의 그림(원형 연결리스트)에서 한바퀴씩 돌면서 현재 0인 곳을 찾아 대체한다.
또한 modified bit이라는 변수도 있는데, write가 이루어진 기록을 저장한다.
이것은 대체할 때 상태를 다시 디스크에 저장하는데에 사용한다.

* Page Frame Allocation
각 프로세스마다 얼마만큼의 프레임을 할당할 것인가도 고려 대상이다.
너무 적게 올리면 페이징폴트가 너무 많이 일어난다. 많아도 문제다.
그래서 균등하게 올리든, 크기에 비례해서 올리든, 우선순위에 따라 올리든 방법이 다양하다.

* 페이지 크기의 결정
- 페이지 크기가 작으면: 페이지 수 증가, 테이블 크기 증가, 디스크 transfer 효율성 감소
그러나 내부 파편화 감소, 필요한 정보만 올릴 수 있어 메모리 활용 효율적
- 페이지 크기가 크면: 위와 반대. 페이지 폴트가 나면 뭔가 큰 데이터가 왔다갔다한다.
큰 페이지 사이즈가 트렌드이긴 하다. 디스크 transfer 효율이 좋다.

* 파일 시스템
파일 open 명령을 내리면 관련 메타데이타들이 메모리로 올라오게 된다.
그리고 read를 했을 때 메모리의 버퍼캐시에 올리고 그것을 읽게 된다.
 